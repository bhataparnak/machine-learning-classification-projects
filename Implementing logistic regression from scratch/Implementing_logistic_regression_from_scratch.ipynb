{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing logistic regression from scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4dRs6byE2dH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peF5RNgzLbmA"
      },
      "source": [
        "Load review dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjwx-fAzLBKj"
      },
      "source": [
        "products = pd.read_csv('/content/amazon_baby_subset.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBpn76iLfIF"
      },
      "source": [
        "listing the name of the first 10 products in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWe79Aq5Li4S",
        "outputId": "e1e73582-fc55-4310-aba4-9a5632641baf"
      },
      "source": [
        "products['name'][:10]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Stop Pacifier Sucking without tears with Thumb...\n",
              "1      Nature's Lullabies Second Year Sticker Calendar\n",
              "2      Nature's Lullabies Second Year Sticker Calendar\n",
              "3                          Lamaze Peekaboo, I Love You\n",
              "4    SoftPlay Peek-A-Boo Where's Elmo A Children's ...\n",
              "5                            Our Baby Girl Memory Book\n",
              "6    Hunnt&reg; Falling Flowers and Birds Kids Nurs...\n",
              "7    Blessed By Pope Benedict XVI Divine Mercy Full...\n",
              "8    Cloth Diaper Pins Stainless Steel Traditional ...\n",
              "9    Cloth Diaper Pins Stainless Steel Traditional ...\n",
              "Name: name, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkp5X4isLx-v"
      },
      "source": [
        "counting the number of positive and negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXdqjxeCLmgP",
        "outputId": "0f3b59ae-111d-42f9-a678-80b5d22a3b87"
      },
      "source": [
        "print ((products['sentiment'] == 1).sum())\n",
        "print ((products['sentiment'] == -1).sum())\n",
        "print ((products['sentiment']).count())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26579\n",
            "26493\n",
            "53072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYR9mnjrMGhL"
      },
      "source": [
        "Apply text cleaning on the review data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDL1BXi3Lz7i",
        "outputId": "5eb45ff2-97ed-44e0-8b00-cd0281acda13"
      },
      "source": [
        "import json\n",
        "with open('/content/important_words.json') as important_words_file:    \n",
        "    important_words = json.load(important_words_file)\n",
        "print(important_words[:3])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['baby', 'one', 'great']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-pgDPg8MQCw"
      },
      "source": [
        "data transformations:\n",
        "\n",
        "fill n/a values in the review column with empty strings.\n",
        "\n",
        "Remove punctuation.\n",
        "\n",
        "Compute word counts (only for important_words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "mqiKNWS4MIMO",
        "outputId": "d122d5b0-bc97-4725-cfb6-b36b9260a2f7"
      },
      "source": [
        "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    import string\n",
        "    return text.translate(string.punctuation) \n",
        "\n",
        "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
        "products.head(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                name  ...                                       review_clean\n",
              "0  Stop Pacifier Sucking without tears with Thumb...  ...  All of my kids have cried non-stop when I trie...\n",
              "1    Nature's Lullabies Second Year Sticker Calendar  ...  We wanted to get something to keep track of ou...\n",
              "2    Nature's Lullabies Second Year Sticker Calendar  ...  My daughter had her 1st baby over a year ago. ...\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9CvmRSzMdMy"
      },
      "source": [
        "Compute a count for the number of times the word occurs in the review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItDfphOtMYlw"
      },
      "source": [
        "for word in important_words:\n",
        "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LKihHVGqMm33",
        "outputId": "d25e6484-f5d3-4fdc-c4ec-0bbf443b7efe"
      },
      "source": [
        "products.head(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_clean</th>\n",
              "      <th>baby</th>\n",
              "      <th>one</th>\n",
              "      <th>great</th>\n",
              "      <th>love</th>\n",
              "      <th>use</th>\n",
              "      <th>would</th>\n",
              "      <th>like</th>\n",
              "      <th>easy</th>\n",
              "      <th>little</th>\n",
              "      <th>seat</th>\n",
              "      <th>old</th>\n",
              "      <th>well</th>\n",
              "      <th>get</th>\n",
              "      <th>also</th>\n",
              "      <th>really</th>\n",
              "      <th>son</th>\n",
              "      <th>time</th>\n",
              "      <th>bought</th>\n",
              "      <th>product</th>\n",
              "      <th>good</th>\n",
              "      <th>daughter</th>\n",
              "      <th>much</th>\n",
              "      <th>loves</th>\n",
              "      <th>stroller</th>\n",
              "      <th>put</th>\n",
              "      <th>months</th>\n",
              "      <th>car</th>\n",
              "      <th>still</th>\n",
              "      <th>back</th>\n",
              "      <th>used</th>\n",
              "      <th>recommend</th>\n",
              "      <th>first</th>\n",
              "      <th>even</th>\n",
              "      <th>perfect</th>\n",
              "      <th>nice</th>\n",
              "      <th>...</th>\n",
              "      <th>looks</th>\n",
              "      <th>second</th>\n",
              "      <th>piece</th>\n",
              "      <th>box</th>\n",
              "      <th>pretty</th>\n",
              "      <th>trying</th>\n",
              "      <th>difficult</th>\n",
              "      <th>together</th>\n",
              "      <th>though</th>\n",
              "      <th>give</th>\n",
              "      <th>started</th>\n",
              "      <th>anything</th>\n",
              "      <th>last</th>\n",
              "      <th>company</th>\n",
              "      <th>come</th>\n",
              "      <th>returned</th>\n",
              "      <th>maybe</th>\n",
              "      <th>took</th>\n",
              "      <th>broke</th>\n",
              "      <th>makes</th>\n",
              "      <th>stay</th>\n",
              "      <th>instead</th>\n",
              "      <th>idea</th>\n",
              "      <th>head</th>\n",
              "      <th>said</th>\n",
              "      <th>less</th>\n",
              "      <th>went</th>\n",
              "      <th>working</th>\n",
              "      <th>high</th>\n",
              "      <th>unit</th>\n",
              "      <th>seems</th>\n",
              "      <th>picture</th>\n",
              "      <th>completely</th>\n",
              "      <th>wish</th>\n",
              "      <th>buying</th>\n",
              "      <th>babies</th>\n",
              "      <th>won</th>\n",
              "      <th>tub</th>\n",
              "      <th>almost</th>\n",
              "      <th>either</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 198 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                name  ... either\n",
              "0  Stop Pacifier Sucking without tears with Thumb...  ...      0\n",
              "\n",
              "[1 rows x 198 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQfx-uZjMv0r"
      },
      "source": [
        "Compute the number of product reviews that contain the word perfect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYXPcuVlMrUZ",
        "outputId": "deb5335d-66ae-4304-c405-4fd7c2747c66"
      },
      "source": [
        "products['contains_perfect'] = products['perfect'] >=1\n",
        "print (products['contains_perfect'].sum())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG4Ja6u3M-k1"
      },
      "source": [
        "Convert data frame to multi-dimensional array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku2t1Zz5M5NG"
      },
      "source": [
        "def get_numpy_data(dataframe, features, label):\n",
        "    dataframe['constant'] = 1\n",
        "    features = ['constant'] + features\n",
        "    features_frame = dataframe[features]\n",
        "    feature_matrix = features_frame.to_numpy()\n",
        "    label_sarray = dataframe[label]\n",
        "    label_array = label_sarray.to_numpy()\n",
        "    return(feature_matrix, label_array)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSoqSAyYNKRL"
      },
      "source": [
        "extract two arrays feature_matrix and sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB0dQxisNGUQ"
      },
      "source": [
        "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYxhEDQGNcLY",
        "outputId": "7709ca0a-a3b6-441d-f1ec-3bb02835c147"
      },
      "source": [
        "print(feature_matrix.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(53072, 194)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWEeDO_5Oct9"
      },
      "source": [
        "Estimating conditional probability with link function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNz9p60TOdrh"
      },
      "source": [
        "'''\n",
        "feature_matrix: N * D\n",
        "coefficients: D * 1\n",
        "predictions: N * 1\n",
        "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
        "estimate ranges between 0 and 1.\n",
        "'''\n",
        "\n",
        "def predict_probability(feature_matrix, coefficients):\n",
        "    # Take dot product of feature_matrix and coefficients  \n",
        "    # YOUR CODE HERE\n",
        "    score = np.dot(feature_matrix, coefficients) # N * 1\n",
        "    \n",
        "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
        "    # YOUR CODE HERE\n",
        "    predictions = 1.0/(1+np.exp(-score))\n",
        "    \n",
        "    # return predictions\n",
        "    return predictions"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFoOnou5OnTJ"
      },
      "source": [
        "Compute derivative of log likelihood with respect to a single coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohDLypk4OjIH"
      },
      "source": [
        "\"\"\"\n",
        "errors: N * 1\n",
        "feature: N * 1\n",
        "derivative: 1 \n",
        "\"\"\"\n",
        "def feature_derivative(errors, feature):     \n",
        "    # Compute the dot product of errors and feature\n",
        "    derivative = np.dot(np.transpose(errors), feature)\n",
        "    # Return the derivative\n",
        "    return derivative"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NneR1xcOucn"
      },
      "source": [
        "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
        "    indicator = (sentiment==+1)\n",
        "    scores = np.dot(feature_matrix, coefficients)\n",
        "    # scores.shape (53072L, 1L)\n",
        "    # indicator.shape (53072L,)\n",
        "    lp = np.sum((np.transpose(np.array([indicator]))-1)*scores - np.log(1. + np.exp(-scores)))\n",
        "    return lp"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNNEapAxO20k"
      },
      "source": [
        "Taking gradient steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A30mV_epOzMk"
      },
      "source": [
        "# coefficients: D * 1\n",
        "from math import sqrt\n",
        "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
        "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
        "    # lplist = []\n",
        "    for itr in range(max_iter):\n",
        "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
        "        # YOUR CODE HERE\n",
        "        predictions = predict_probability(feature_matrix, coefficients)\n",
        "\n",
        "        # Compute indicator value for (y_i = +1)\n",
        "        indicator = (sentiment==+1)\n",
        "\n",
        "        # Compute the errors as indicator - predictions\n",
        "        errors = np.transpose(np.array([indicator])) - predictions\n",
        "\n",
        "        for j in range(len(coefficients)): # loop over each coefficient\n",
        "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
        "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
        "            # YOUR CODE HERE\n",
        "            derivative = feature_derivative(errors, feature_matrix[:,j])\n",
        "\n",
        "            # add the step size times the derivative to the current coefficient\n",
        "            # YOUR CODE HERE\n",
        "            coefficients[j] += step_size*derivative\n",
        "\n",
        "        # Checking whether log likelihood is increasing\n",
        "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
        "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
        "            # lplist.append(compute_log_likelihood(feature_matrix, sentiment, coefficients))\n",
        "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
        "            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
        "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    x= [i for i in range(len(lplist))]\n",
        "    plt.plot(x,lplist,'ro')\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "    return coefficients"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwZgUgSPTDT"
      },
      "source": [
        "run the logistic regression solver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bniiL9J5PPma"
      },
      "source": [
        "initial_coefficients = np.zeros((194,1))\n",
        "step_size = 1e-7\n",
        "max_iter = 301"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvJywxeFPUXC",
        "outputId": "a74cb5db-fc62-4402-ed02-bd65beb0578d"
      },
      "source": [
        "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration   0: log likelihood of observed labels = -36782.24149905\n",
            "iteration   1: log likelihood of observed labels = -36777.77993493\n",
            "iteration   2: log likelihood of observed labels = -36773.32246359\n",
            "iteration   3: log likelihood of observed labels = -36768.86907436\n",
            "iteration   4: log likelihood of observed labels = -36764.41975666\n",
            "iteration   5: log likelihood of observed labels = -36759.97449997\n",
            "iteration   6: log likelihood of observed labels = -36755.53329383\n",
            "iteration   7: log likelihood of observed labels = -36751.09612785\n",
            "iteration   8: log likelihood of observed labels = -36746.66299174\n",
            "iteration   9: log likelihood of observed labels = -36742.23387522\n",
            "iteration  10: log likelihood of observed labels = -36737.80876812\n",
            "iteration  11: log likelihood of observed labels = -36733.38766031\n",
            "iteration  12: log likelihood of observed labels = -36728.97054176\n",
            "iteration  13: log likelihood of observed labels = -36724.55740245\n",
            "iteration  14: log likelihood of observed labels = -36720.14823248\n",
            "iteration  15: log likelihood of observed labels = -36715.74302197\n",
            "iteration  20: log likelihood of observed labels = -36693.77602065\n",
            "iteration  30: log likelihood of observed labels = -36650.13348177\n",
            "iteration  40: log likelihood of observed labels = -36606.87197329\n",
            "iteration  50: log likelihood of observed labels = -36563.98286427\n",
            "iteration  60: log likelihood of observed labels = -36521.45802595\n",
            "iteration  70: log likelihood of observed labels = -36479.28979071\n",
            "iteration  80: log likelihood of observed labels = -36437.47091460\n",
            "iteration  90: log likelihood of observed labels = -36395.99454329\n",
            "iteration 100: log likelihood of observed labels = -36354.85418097\n",
            "iteration 200: log likelihood of observed labels = -35960.70841629\n",
            "iteration 300: log likelihood of observed labels = -35594.84598974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVkPCidkQbmo"
      },
      "source": [
        "Compute class predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81t84YsnP-7F",
        "outputId": "896f1ebb-ca2a-4465-ba6b-bfac29826707"
      },
      "source": [
        "\"\"\"\n",
        "feature_matrix: N * D\n",
        "coefficients: D * 1\n",
        "predictions: N * 1\n",
        "\"\"\"\n",
        "predictions = predict_probability(feature_matrix, coefficients)\n",
        "NumPositive = (predictions > 0.5).sum()\n",
        "print (NumPositive)\n",
        "\n",
        "score = np.dot(feature_matrix, coefficients) # N * 1\n",
        "print ((score > 0).sum())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24714\n",
            "24714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3_ZzPXaRHBU"
      },
      "source": [
        "Measuring accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBHWcUAFQel9",
        "outputId": "85a76057-a917-4891-fd46-2b5c10271ef0"
      },
      "source": [
        "print (0 in products['sentiment'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZojYVc-Qleo",
        "outputId": "63addf91-3248-4e11-99ce-d0edc9422f18"
      },
      "source": [
        "print (-1 in products['sentiment'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbtRoVVGQpX_",
        "outputId": "53369db7-fc42-480a-ade3-581a113f9198"
      },
      "source": [
        "print (np.transpose(predictions.flatten()).shape)\n",
        "print ((products['sentiment']).shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(53072,)\n",
            "(53072,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpU3EugnQwcV",
        "outputId": "6120546e-68a2-412c-9a0c-fbcb76a157d8"
      },
      "source": [
        "print ((np.transpose(predictions.flatten()))[:5])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.50977952 0.49260815 0.50289701 0.50055279 0.52735675]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix2EGAohQ3Le",
        "outputId": "93dc65f6-3be5-43a4-beae-29749b169099"
      },
      "source": [
        "correct_num = np.sum((np.transpose(predictions.flatten())> 0.5) == np.array(products['sentiment']>0))\n",
        "total_num = len(products['sentiment'])\n",
        "print (\"correct_num: {}, total_num: {}\".format(correct_num, total_num))\n",
        "accuracy = correct_num * 1./ total_num\n",
        "print (accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct_num: 39117, total_num: 53072\n",
            "0.737055321073259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTmPWTaIRIbn",
        "outputId": "9ee56981-98e2-4be1-c67c-9c32be62d782"
      },
      "source": [
        "np.transpose(predictions.flatten())> 0.5"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False,  True, ..., False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu-KroZJRNjp",
        "outputId": "f33c713c-8bbf-4797-cbc6-093dd8ac9e7a"
      },
      "source": [
        "np.array(products['sentiment']>0)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ..., False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX-Mr1mkRRCK",
        "outputId": "be963022-7d99-42fc-be55-3bae5026572f"
      },
      "source": [
        "correct_num = np.sum((np.transpose(score.flatten())> 0) == np.array(products['sentiment']>0))\n",
        "total_num = len(products['sentiment'])\n",
        "print (\"correct_num: {}, total_num: {}\".format(correct_num, total_num))\n",
        "accuracy = correct_num * 1./ total_num\n",
        "print (accuracy)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct_num: 39117, total_num: 53072\n",
            "0.737055321073259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwrob_whRhyY"
      },
      "source": [
        "Compute the \"most positive words\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAcfJwoHRc0Z"
      },
      "source": [
        "coefficients = list(coefficients[1:]) # exclude intercept\n",
        "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
        "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzyLAz4WRnUd"
      },
      "source": [
        "Compute the 10 most positive words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vti3KOAxRr8w",
        "outputId": "bec3746a-c3d5-4357-ddea-6da8b57e1aaa"
      },
      "source": [
        "word_coefficient_tuples[:10]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', array([0.06516289])),\n",
              " ('easy', array([0.06202955])),\n",
              " ('great', array([0.05068325])),\n",
              " ('little', array([0.04496421])),\n",
              " ('loves', array([0.04487736])),\n",
              " ('perfect', array([0.02268598])),\n",
              " ('well', array([0.02069822])),\n",
              " ('fits', array([0.01708208])),\n",
              " ('nice', array([0.01654066])),\n",
              " ('daughter', array([0.01645556]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXS8lSiERxFC"
      },
      "source": [
        "Ten \"most negative\" words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATeFsnjoR3OY",
        "outputId": "0fcbc9a8-49f2-4274-e37b-71b6c7dc292c"
      },
      "source": [
        "word_coefficient_tuples[-10:]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('monitor', array([-0.02068181])),\n",
              " ('thought', array([-0.02075643])),\n",
              " ('work', array([-0.02094667])),\n",
              " ('money', array([-0.02235262])),\n",
              " ('waste', array([-0.02315535])),\n",
              " ('return', array([-0.02457066])),\n",
              " ('get', array([-0.029324])),\n",
              " ('even', array([-0.03021414])),\n",
              " ('product', array([-0.03617626])),\n",
              " ('would', array([-0.05387976]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}